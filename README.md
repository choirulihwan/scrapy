# scrapy
<h1>repository for works on scrapy</h1>

# step by step
- scrapy startproject [nama_project]
- scrapy genspider [nama_spider] [nama_domain] => membuat spider
- create python file in [nama_project]/spiders (optional)

# Test
- scrapy shell [url]
- scrapy crawl [nama_crawl] 

# Output
- scrapy crawl [nama_crawl] -o [nama_file.json|csv]

# Keterangan
Untuk melihat page yang boleh discrape dilihat dari robots.txt misal amazone.com/robots.txt

